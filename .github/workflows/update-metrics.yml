name: Update GitHub Metrics

on:
  schedule:
    - cron: "0 0 * * *"    # Daily at midnight UTC
  workflow_dispatch:       # Manual trigger for testing

jobs:
  update-metrics:
    runs-on: ubuntu-latest

    permissions:
      contents: write

    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Verify dependencies
        run: |
          echo "Checking gh CLI..."
          gh --version
          echo "Checking jq..."
          jq --version

      - name: Collect metrics via GraphQL
        env:
          GH_TOKEN: ${{ secrets.METRICS_TOKEN }}
          USERNAME: foyzulkarim
        run: |
          set -e

          echo "Fetching metrics for $USERNAME..."

          # GraphQL query for stars, forks, watchers, repo count, followers
          QUERY='
          query($username: String!, $cursor: String) {
            user(login: $username) {
              followers {
                totalCount
              }
              repositories(first: 100, after: $cursor, ownerAffiliations: OWNER, isFork: false) {
                totalCount
                pageInfo {
                  hasNextPage
                  endCursor
                }
                nodes {
                  name
                  stargazerCount
                  forkCount
                  watchers {
                    totalCount
                  }
                }
              }
            }
          }'

          total_stars=0
          total_forks=0
          total_watchers=0
          total_repos=0
          total_followers=0
          cursor="null"
          page=1
          empty_pages=0
          max_pages=50  # Safety limit - user has ~78 repos, should need 1 page max

          while true; do
            # Safety check: prevent infinite loops
            if [ "$page" -gt "$max_pages" ]; then
              echo "Warning: Reached max page limit ($max_pages). Breaking to prevent infinite loop."
              break
            fi
            echo "Fetching page $page..."

            if [ "$cursor" = "null" ]; then
              # Capture full API response for debugging
              api_output=$(gh api graphql \
                -f query="$QUERY" \
                -f username="$USERNAME" 2>&1) || {
                echo "ERROR: GraphQL API call failed"
                echo "Response: $api_output"
              }
              full_response=$(echo "$api_output" | jq -r '.data.user // {}')
              response=$(echo "$full_response" | jq '.repositories // {}')
              # Get followers only on first page
              total_followers=$(echo "$full_response" | jq -r '.followers.totalCount // 0' | tr -d '\n')
              # Ensure total_followers is numeric
              [[ "$total_followers" =~ ^[0-9]+$ ]] || total_followers=0
            else
              response=$(gh api graphql \
                -f query="$QUERY" \
                -f username="$USERNAME" \
                -f cursor="$cursor" \
                --jq '.data.user.repositories' 2>/dev/null || echo "{}")
            fi

            # Parse response
            has_next=$(echo "$response" | jq -r '.pageInfo.hasNextPage // false')
            cursor=$(echo "$response" | jq -r '.pageInfo.endCursor // "null"')

            # Set total_repos only once (same value on all pages)
            if [ "$page" -eq 1 ]; then
              total_repos=$(echo "$response" | jq -r '.totalCount // 0' | tr -d '\n')
              # Ensure total_repos is numeric
              [[ "$total_repos" =~ ^[0-9]+$ ]] || total_repos=0
              # Debug: show what we got from API
              echo "  DEBUG: totalCount=$total_repos, followers=$total_followers"
              echo "  DEBUG: nodes count=$(echo "$response" | jq '.nodes | length // 0')"
            fi

            # Sum metrics from this page with null/empty safety (using ? for optional iteration)
            page_stars=$(echo "$response" | jq '[.nodes[]?.stargazerCount // 0] | add // 0')
            page_forks=$(echo "$response" | jq '[.nodes[]?.forkCount // 0] | add // 0')
            page_watchers=$(echo "$response" | jq '[.nodes[]?.watchers?.totalCount // 0] | add // 0')

            # Ensure values are numeric (default to 0 if empty or null)
            page_stars=${page_stars:-0}
            page_forks=${page_forks:-0}
            page_watchers=${page_watchers:-0}
            [[ "$page_stars" =~ ^[0-9]+$ ]] || page_stars=0
            [[ "$page_forks" =~ ^[0-9]+$ ]] || page_forks=0
            [[ "$page_watchers" =~ ^[0-9]+$ ]] || page_watchers=0

            total_stars=$((total_stars + page_stars))
            total_forks=$((total_forks + page_forks))
            total_watchers=$((total_watchers + page_watchers))

            echo "  Page $page: +$page_stars stars, +$page_forks forks, +$page_watchers watchers"

            # Track consecutive empty pages to detect potential infinite loops
            if [ "$page_stars" -eq 0 ] && [ "$page_forks" -eq 0 ] && [ "$page_watchers" -eq 0 ]; then
              empty_pages=$((empty_pages + 1))
              if [ "$empty_pages" -ge 3 ]; then
                echo "Warning: $empty_pages consecutive empty pages. Breaking to prevent potential infinite loop."
                break
              fi
            else
              empty_pages=0
            fi

            # Break if no more pages or invalid response
            if [ "$has_next" != "true" ]; then
              break
            fi

            # Also break if cursor is empty or null (API returned invalid pagination)
            if [ -z "$cursor" ] || [ "$cursor" = "null" ] || [ "$cursor" = "" ]; then
              echo "Warning: Invalid cursor received. Breaking pagination."
              break
            fi
            page=$((page + 1))
            sleep 1  # Rate limit protection
          done

          echo ""
          echo "Fetching traffic views..."

          # Get repo names for traffic API (REST only, with pagination)
          total_views=0
          traffic_page=1
          views_data=""

          while true; do
            repos=$(gh api "users/$USERNAME/repos?per_page=100&page=$traffic_page&type=owner" --jq '.[].name' 2>/dev/null || echo "")

            # Break if no repos returned
            [ -z "$repos" ] && break

            for repo in $repos; do
              views=$(gh api "repos/$USERNAME/$repo/traffic/views" --jq '.count // 0' 2>/dev/null || echo "0")
              # Ensure views is numeric
              [[ "$views" =~ ^[0-9]+$ ]] || views=0
              total_views=$((total_views + views))
              if [ "$views" -gt 0 ]; then
                echo "  $repo: $views views"
                views_data="${views_data}${views} ${repo}"$'\n'
              fi
              sleep 0.5  # Rate limit protection
            done

            # Check if we got less than 100 repos (last page)
            repo_count=$(echo "$repos" | wc -l)
            [ "$repo_count" -lt 100 ] && break

            traffic_page=$((traffic_page + 1))
          done

          # Sort by views (descending) and take top 10
          TOP_REPOS_COUNT=10
          echo ""
          echo "=== Top $TOP_REPOS_COUNT Repositories by Views ==="
          top_repos_table="| Repository | Views |"$'\n'
          top_repos_table+="|------------|-------|"$'\n'

          top_repos=$(echo "$views_data" | sort -t' ' -k1 -nr | head -n $TOP_REPOS_COUNT)
          while IFS= read -r line; do
            [ -z "$line" ] && continue
            repo_views=$(echo "$line" | cut -d' ' -f1)
            repo_name=$(echo "$line" | cut -d' ' -f2-)
            echo "  $repo_name: $repo_views views"
            top_repos_table+="| [$repo_name](https://github.com/$USERNAME/$repo_name) | $repo_views |"$'\n'
          done <<< "$top_repos"

          # Export top repos table (use delimiter for multiline)
          echo "TOP_REPOS_TABLE<<EOF" >> $GITHUB_ENV
          echo "$top_repos_table" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

          echo ""
          echo "=== Final Metrics ==="

          # Final sanitization - ensure all values are single-line integers
          total_repos=$(echo "$total_repos" | tr -d '\n\r' | grep -oE '^[0-9]+$' || echo "0")
          total_stars=$(echo "$total_stars" | tr -d '\n\r' | grep -oE '^[0-9]+$' || echo "0")
          total_forks=$(echo "$total_forks" | tr -d '\n\r' | grep -oE '^[0-9]+$' || echo "0")
          total_watchers=$(echo "$total_watchers" | tr -d '\n\r' | grep -oE '^[0-9]+$' || echo "0")
          total_followers=$(echo "$total_followers" | tr -d '\n\r' | grep -oE '^[0-9]+$' || echo "0")
          total_views=$(echo "$total_views" | tr -d '\n\r' | grep -oE '^[0-9]+$' || echo "0")

          echo "Repositories: $total_repos"
          echo "Stars: $total_stars"
          echo "Forks: $total_forks"
          echo "Watchers: $total_watchers"
          echo "Followers: $total_followers"
          echo "Views (14 days): $total_views"

          # Export to environment
          echo "TOTAL_REPOS=$total_repos" >> $GITHUB_ENV
          echo "TOTAL_STARS=$total_stars" >> $GITHUB_ENV
          echo "TOTAL_FORKS=$total_forks" >> $GITHUB_ENV
          echo "TOTAL_WATCHERS=$total_watchers" >> $GITHUB_ENV
          echo "TOTAL_FOLLOWERS=$total_followers" >> $GITHUB_ENV
          echo "TOTAL_VIEWS=$total_views" >> $GITHUB_ENV
          echo "LAST_UPDATED=$(date -u '+%Y-%m-%d %H:%M UTC')" >> $GITHUB_ENV

      - name: Update README
        run: |
          sed -i "s|<!--TOTAL_REPOS-->.*<!--/TOTAL_REPOS-->|<!--TOTAL_REPOS-->${TOTAL_REPOS}<!--/TOTAL_REPOS-->|" README.md
          sed -i "s|<!--TOTAL_STARS-->.*<!--/TOTAL_STARS-->|<!--TOTAL_STARS-->${TOTAL_STARS}<!--/TOTAL_STARS-->|" README.md
          sed -i "s|<!--TOTAL_FORKS-->.*<!--/TOTAL_FORKS-->|<!--TOTAL_FORKS-->${TOTAL_FORKS}<!--/TOTAL_FORKS-->|" README.md
          sed -i "s|<!--TOTAL_WATCHERS-->.*<!--/TOTAL_WATCHERS-->|<!--TOTAL_WATCHERS-->${TOTAL_WATCHERS}<!--/TOTAL_WATCHERS-->|" README.md
          sed -i "s|<!--TOTAL_FOLLOWERS-->.*<!--/TOTAL_FOLLOWERS-->|<!--TOTAL_FOLLOWERS-->${TOTAL_FOLLOWERS}<!--/TOTAL_FOLLOWERS-->|" README.md
          sed -i "s|<!--TOTAL_VIEWS-->.*<!--/TOTAL_VIEWS-->|<!--TOTAL_VIEWS-->${TOTAL_VIEWS}<!--/TOTAL_VIEWS-->|" README.md
          sed -i "s|<!--LAST_UPDATED-->.*<!--/LAST_UPDATED-->|<!--LAST_UPDATED-->${LAST_UPDATED}<!--/LAST_UPDATED-->|" README.md

          # Replace top repos table (multiline)
          awk -v table="$TOP_REPOS_TABLE" '
            /<!--TOP_REPOS_START-->/ { print; print table; skip=1; next }
            /<!--TOP_REPOS_END-->/ { skip=0 }
            !skip { print }
          ' README.md > README.tmp && mv README.tmp README.md

      - name: Update metrics history (rolling 365 days)
        run: |
          python3 << 'PYTHON_EOF'
          import json
          import os
          from datetime import datetime, timedelta

          # Get today's date
          today = datetime.now().strftime("%Y-%m-%d")

          # Metrics history file path (in docs/ for GitHub Pages)
          metrics_file = 'docs/metrics-history.json'

          # Load existing metrics history
          try:
              with open(metrics_file, 'r') as f:
                  data = json.load(f)
          except FileNotFoundError:
              data = {"metrics": []}

          # Create today's metric entry
          today_metric = {
              "date": today,
              "repositories": int(os.environ.get('TOTAL_REPOS', 0)),
              "stars": int(os.environ.get('TOTAL_STARS', 0)),
              "forks": int(os.environ.get('TOTAL_FORKS', 0)),
              "watchers": int(os.environ.get('TOTAL_WATCHERS', 0)),
              "followers": int(os.environ.get('TOTAL_FOLLOWERS', 0)),
              "views_14d": int(os.environ.get('TOTAL_VIEWS', 0))
          }

          # Remove today's entry if it exists (to avoid duplicates)
          data["metrics"] = [m for m in data["metrics"] if m["date"] != today]

          # Add today's data
          data["metrics"].append(today_metric)

          # Keep only last 365 days
          cutoff_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
          data["metrics"] = [m for m in data["metrics"] if m["date"] >= cutoff_date]

          # Save updated metrics history
          with open(metrics_file, 'w') as f:
              json.dump(data, f, indent=2)

          print(f"Updated {metrics_file} with {len(data['metrics'])} days of data")
          PYTHON_EOF
        env:
          TOTAL_REPOS: ${{ env.TOTAL_REPOS }}
          TOTAL_STARS: ${{ env.TOTAL_STARS }}
          TOTAL_FORKS: ${{ env.TOTAL_FORKS }}
          TOTAL_WATCHERS: ${{ env.TOTAL_WATCHERS }}
          TOTAL_FOLLOWERS: ${{ env.TOTAL_FOLLOWERS }}
          TOTAL_VIEWS: ${{ env.TOTAL_VIEWS }}

      - name: Commit and push
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Check if there are changes in README or metrics history
          if ! git diff --quiet README.md docs/metrics-history.json; then
            git add README.md docs/metrics-history.json
            git commit -m "chore: update GitHub metrics [skip ci]"
            # Pull with rebase to handle any concurrent updates, then push
            git pull --rebase origin ${{ github.ref_name }} || true
            git push
            echo "Metrics updated successfully!"
          else
            echo "No changes to commit."
          fi
